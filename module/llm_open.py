#module/llm_open.py
import streamlit as st
from openai import OpenAI
import json
import logging
import re
import tiktoken
import pandas as pd


# üöÄ Obtendo a chave da API do OpenAI do arquivo secrets.toml
try:
    OPENAI_API_KEY = st.secrets["openai"]["api_key"]
    print("üîë API Key:", st.secrets["openai"]["api_key"])
except Exception as e:
    print("‚ùå ERRO ao acessar o secrets.toml:", e)


# ‚úÖ Configura o cliente OpenAI com a chave da API
cliente_openai = OpenAI(api_key=OPENAI_API_KEY)

def dividir_texto(texto, modelo="gpt-4o-mini", limite_tokens=4000, overlap=200):
    """
    Divide um texto longo em partes menores para envio √† API, garantindo que n√£o haja perda de contexto.

    Args:
        texto (str): Texto completo a ser dividido.
        modelo (str): Modelo OpenAI usado para calcular os tokens.
        limite_tokens (int): N√∫mero m√°ximo de tokens por bloco.
        overlap (int): N√∫mero de tokens repetidos entre blocos para manter o contexto.

    Returns:
        list: Lista de blocos de texto processados.
    """
    codificacao = tiktoken.encoding_for_model(modelo)

    # üõ†Ô∏è Melhor abordagem: Dividir por par√°grafos em vez de senten√ßas individuais
    paragrafos = texto.strip().split("\n\n")  # Par√°grafos s√£o separados por duas quebras de linha

    blocos = []
    bloco_atual = []
    tokens_acumulados = 0

    for paragrafo in paragrafos:
        tokens_paragrafo = len(codificacao.encode(paragrafo))

        # Se ultrapassar o limite, fecha o bloco atual e inicia um novo
        if tokens_acumulados + tokens_paragrafo > limite_tokens:
            blocos.append("\n\n".join(bloco_atual))  # Preservando separa√ß√£o original
            sobreposicao = bloco_atual[-(overlap // tokens_paragrafo):] if bloco_atual else []
            bloco_atual = sobreposicao.copy()
            tokens_acumulados = sum(len(codificacao.encode(p)) for p in bloco_atual)

        bloco_atual.append(paragrafo)
        tokens_acumulados += tokens_paragrafo

    if bloco_atual:
        blocos.append("\n\n".join(bloco_atual))

    return blocos

def executar_openai(prompt):
    """
    Executa a API OpenAI com o prompt fornecido e retorna um DataFrame.

    Args:
        prompt (str): Instru√ß√µes para a API OpenAI.

    Returns:
        pd.DataFrame: DataFrame contendo os dados extra√≠dos da resposta JSON.
    """
    try:
        logging.info("üîç Enviando requisi√ß√£o para OpenAI...")

        resposta = cliente_openai.chat.completions.create(
            model="gpt-4o-mini",  # Modelo atualizado para um mais confi√°vel
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Voc√™ √© um assistente especializado em extra√ß√£o de dados financeiros, "
                        "com foco em an√°lise e processamento de extratos banc√°rios."
                    )
                },
                {"role": "user", "content": prompt},
            ],
            max_tokens=16383,
            temperature=0.5,
            response_format={"type": "json_object"},  # Corrigido para garantir resposta JSON v√°lida
        )

        texto_resposta = resposta.choices[0].message.content.strip()

        # üìå Remover delimitadores ```json e ``` se existirem
        if texto_resposta.startswith("```json") and texto_resposta.endswith("```"):
            texto_resposta = texto_resposta[7:-3].strip()

        # üìå Garantir que a resposta seja um JSON v√°lido antes de converter
        try:
            dados = json.loads(texto_resposta)

            # üìå Se os dados retornados forem um dicion√°rio, tente extrair a lista correta
            if isinstance(dados, dict):
                # Verifica se h√° uma chave principal contendo a lista de transa√ß√µes
                for key in dados:
                    if isinstance(dados[key], list):
                        dados = dados[key]
                        break

            if not isinstance(dados, list):
                raise ValueError("A resposta da OpenAI n√£o cont√©m uma lista de transa√ß√µes.")

        except json.JSONDecodeError as erro_json:
            logging.error(f"‚ùå ERRO: A resposta da API n√£o √© um JSON v√°lido! {erro_json}")
            return pd.DataFrame(columns=["Data", "Hist√≥rico", "Documento", "D√©bito/Cr√©dito", "Valor R$", "Origem/Destino", "Banco"])

        # üìå Converter JSON para DataFrame
        df = pd.DataFrame(dados)

        # ‚úÖ Verificar se a resposta cont√©m os campos esperados
        colunas_esperadas = ["Data", "Hist√≥rico", "Documento", "D√©bito/Cr√©dito", "Valor R$", "Origem/Destino", "Banco"]
        for coluna in colunas_esperadas:
            if coluna not in df.columns:
                logging.warning(f"‚ö†Ô∏è A coluna esperada '{coluna}' n√£o est√° presente na resposta.")

        return df

    except Exception as erro:
        logging.error(f"‚ùå ERRO ao conectar √† OpenAI API: {erro}")
        return pd.DataFrame(columns=["Data", "Hist√≥rico", "Documento", "D√©bito/Cr√©dito", "Valor R$", "Origem/Destino", "Banco"])